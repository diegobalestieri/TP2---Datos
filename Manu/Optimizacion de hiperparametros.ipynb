{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizacion de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "def objective(space):\n",
    "    # Instantiate the classifier con los nuevos hyperparametros\n",
    "    clf = xgb.XGBClassifier(n_estimators =1000,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = .3,\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],\n",
    "                           tree_method='gpu_hist', gpu_id=0)\n",
    "    \n",
    "    eval_set  = [( X, y), ( Xcv, ycv)]\n",
    "    \n",
    "    # Fit the classsifier\n",
    "    clf.fit(X, y,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "    # Predict on Cross Validation data\n",
    "    pred = clf.predict(Xcv)\n",
    "    \n",
    "    # Calculate our Metric - accuracy\n",
    "    accuracy = accuracy_score(ycv, pred>0.5)\n",
    "\n",
    "    # return needs to be in this below format. We use negative of accuracy since we want to maximize it.\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino mis posibles hiperparametros\n",
    "#Notese que usa distribuciones para definir los hiperparametros\n",
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.5),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco el mejor\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
