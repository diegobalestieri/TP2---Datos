{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/tp2datostrain/test.csv\n/kaggle/input/tp2datostrain/train.csv\n/kaggle/input/pingsound/PING - Sound effect.mp3\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom category_encoders import CountEncoder\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Audio\nsound_file = '/kaggle/input/pingsound/PING - Sound effect.mp3'\ndef ping():\n    display(Audio(sound_file, autoplay=True))","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntest = pd.read_csv(\"../input/tp2datostrain/test.csv\")\ntrain = pd.read_csv(\"../input/tp2datostrain/train.csv\")","execution_count":160,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separo un pedazo del test de train para testear luego...\nPORCENTAJE_A_SEPARAR = 0.1\nfilas_totales = train.shape[0]\n\ndf_test = train.tail(int(filas_totales * PORCENTAJE_A_SEPARAR)).copy()\ndf_test.shape","execution_count":161,"outputs":[{"output_type":"execute_result","execution_count":161,"data":{"text/plain":"(24000, 23)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCheto = pd.concat([train,test], sort=False)\ndfCheto['precio'] = SimpleImputer(strategy='median').fit_transform(dfCheto[['precio']])\ndfCheto = train.head(int(filas_totales * (100 - PORCENTAJE_A_SEPARAR)))\ndf = dfCheto.copy()\n\n#train = aux.head(150000)\n#test = aux.tail(90000)\n#test.drop(columns=['precio'],inplace =True)\n#dfCheto = pd.concat([train,test], sort=False)","execution_count":162,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ciudades = list(dfCheto[\"ciudad\"].unique())\ntipos_de_propiedad = list(dfCheto[\"tipodepropiedad\"].unique())\nprovincia = list(dfCheto[\"provincia\"].unique())\ncategorias  = [provincia, tipos_de_propiedad, ciudades]","execution_count":163,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":164,"outputs":[{"output_type":"execute_result","execution_count":164,"data":{"text/plain":"Index(['id', 'titulo', 'descripcion', 'tipodepropiedad', 'direccion', 'ciudad',\n       'provincia', 'antiguedad', 'habitaciones', 'garages', 'banos',\n       'metroscubiertos', 'metrostotales', 'idzona', 'lat', 'lng', 'fecha',\n       'gimnasio', 'usosmultiples', 'piscina', 'escuelascercanas',\n       'centroscomercialescercanos', 'precio'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux2 = dfCheto[['ciudad', 'provincia']].copy()\naux2.dropna(inplace = True)\naux2 = aux2.groupby(['provincia']).agg(lambda x:x.provincia.value_counts().index[0]).reset_index().set_index('ciudad')\ndicc_ciudadPorPcia = aux2.T.to_dict('records').copy()[0]\ndicc_ciudadPorPcia['CUALQUIERA'] = 'CUALQUIERCIUDAD'\ndf['ciudad'] =df['ciudad'].fillna('CUALQUIERA')\ndf['provincia'] = df['provincia'].fillna(df['ciudad'].map(dicc_ciudadPorPcia))","execution_count":165,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.provincia.fillna('provinciaVacia',inplace=True)","execution_count":166,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['provincia'].isna().sum()","execution_count":167,"outputs":[{"output_type":"execute_result","execution_count":167,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux2 = dfCheto[['ciudad', 'provincia']].copy()\naux2 = aux2.groupby(['provincia']).agg(lambda x:x.provincia.value_counts().index[0]).reset_index().set_index('ciudad')\naux2.head()\ndicc_ciudadMasFrecuentePorPcia = aux2.T.to_dict('records').copy()[0]\ndicc_invertido = dict(map(reversed, dicc_ciudadMasFrecuentePorPcia.items()))\ndf.ciudad.fillna(df.provincia.map(dicc_invertido),inplace=True);\ndf.ciudad.isna().sum()","execution_count":168,"outputs":[{"output_type":"execute_result","execution_count":168,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.ciudad.fillna('ciudadVacia',inplace=True)","execution_count":169,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tipodepropiedad.fillna('tipoVacio',inplace=True)\n'''\nauxmetros = df[['tipodepropiedad','metrostotales']].copy()\nauxmetros = auxmetros.groupby('tipodepropiedad')['metrostotales'].mean().sort_values().reset_index()\nlista = sorted(auxmetros.metrostotales.tolist())\nlista_2 = [0]*len(lista)\nfor i,numero in enumerate(lista):\n    if i == 0: lista_2[i] = (0,numero)\n    else:\n        lista_2[i] = (lista[i-1],lista[i])\nrangoMetros = pd.Series(lista_2).sort_values()\nauxmetros['rangoMetros'] = rangoMetros\nauxmetros = auxmetros.set_index('tipodepropiedad').drop(columns='metrostotales')\ndicc_tipoDeProp = auxmetros.T.to_dict('records').copy()[0]\ndef mapearMetros(metrostotales,dicc_tipoDeProp):\n    for clave in dicc_tipoDeProp:\n        if metrostotales >= dicc_tipoDeProp[clave][0] and metrostotales < dicc_tipoDeProp[clave][1]: return clave\n    return 'Casa'\ndf.tipodepropiedad.fillna(df.metrostotales.map(lambda x: mapearMetros(x,dicc_tipoDeProp)),inplace=True);\ndf.tipodepropiedad.isna().sum()\n'''","execution_count":170,"outputs":[{"output_type":"execute_result","execution_count":170,"data":{"text/plain":"\"\\nauxmetros = df[['tipodepropiedad','metrostotales']].copy()\\nauxmetros = auxmetros.groupby('tipodepropiedad')['metrostotales'].mean().sort_values().reset_index()\\nlista = sorted(auxmetros.metrostotales.tolist())\\nlista_2 = [0]*len(lista)\\nfor i,numero in enumerate(lista):\\n    if i == 0: lista_2[i] = (0,numero)\\n    else:\\n        lista_2[i] = (lista[i-1],lista[i])\\nrangoMetros = pd.Series(lista_2).sort_values()\\nauxmetros['rangoMetros'] = rangoMetros\\nauxmetros = auxmetros.set_index('tipodepropiedad').drop(columns='metrostotales')\\ndicc_tipoDeProp = auxmetros.T.to_dict('records').copy()[0]\\ndef mapearMetros(metrostotales,dicc_tipoDeProp):\\n    for clave in dicc_tipoDeProp:\\n        if metrostotales >= dicc_tipoDeProp[clave][0] and metrostotales < dicc_tipoDeProp[clave][1]: return clave\\n    return 'Casa'\\ndf.tipodepropiedad.fillna(df.metrostotales.map(lambda x: mapearMetros(x,dicc_tipoDeProp)),inplace=True);\\ndf.tipodepropiedad.isna().sum()\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux2 = dfCheto[['idzona', 'ciudad']].copy()\naux2.dropna(inplace = True)\naux2 = aux2.groupby('ciudad').agg({'idzona':'median'})\nids = aux2.T.to_dict('records').copy()\nids = ids[0]\ndf.idzona.fillna(df.ciudad.map(ids), inplace = True)","execution_count":171,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['idzona'] = SimpleImputer(strategy='most_frequent').fit_transform(df[['idzona']])","execution_count":172,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['lat', 'ciudad']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('ciudad').agg({'lat':'mean'})\nlats = aux.T.to_dict('records').copy()\nlats = lats[0]\ndf.lat.fillna(df.ciudad.map(lats), inplace = True)","execution_count":173,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lat'] = SimpleImputer(strategy='most_frequent').fit_transform(df[['lat']])","execution_count":174,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['lng', 'ciudad']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('ciudad').agg({'lng':'mean'})\nlngs = aux.T.to_dict('records').copy()\nlngs = lngs[0]\ndf.lng.fillna(df.ciudad.map(lngs), inplace = True)","execution_count":175,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lng'] = SimpleImputer(strategy='most_frequent').fit_transform(df[['lng']])","execution_count":176,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['tipodepropiedad', 'habitaciones']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('tipodepropiedad').agg({'habitaciones':'median'})\nhabts = aux.T.to_dict('records').copy()\nhabts = habts[0]\ndf.habitaciones.fillna(df.tipodepropiedad.map(habts), inplace = True)","execution_count":177,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['habitaciones'] = SimpleImputer(strategy='most_frequent').fit_transform(df[['habitaciones']])","execution_count":178,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['tipodepropiedad', 'garages']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('tipodepropiedad').agg({'garages':'median'})\nhabts = aux.T.to_dict('records').copy()\nhabts = habts[0]\ndf.garages.fillna(df.tipodepropiedad.map(habts), inplace = True)","execution_count":179,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.garages.fillna(0, inplace=True)","execution_count":180,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['direccion'], inplace=True)","execution_count":181,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['antiguedad', 'ciudad']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('ciudad').agg({'antiguedad':'mean'})\nlngs = aux.T.to_dict('records').copy()\nlngs = lngs[0]\ndf.antiguedad.fillna(df.ciudad.map(lngs), inplace = True)","execution_count":182,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['antiguedad'] = SimpleImputer(strategy='most_frequent').fit_transform(df[['antiguedad']])","execution_count":183,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = dfCheto[['banos', 'tipodepropiedad']].copy()\naux.dropna(inplace = True)\naux = aux.groupby('tipodepropiedad').agg({'banos':'median'})\nlngs = aux.T.to_dict('records').copy()\nlngs = lngs[0]\ndf.banos.fillna(df.tipodepropiedad.map(lngs), inplace = True)","execution_count":184,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.banos.fillna(1, inplace=True)","execution_count":185,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = df.copy()","execution_count":186,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux.metrostotales.fillna(0, inplace=True)\naux.metroscubiertos.fillna(0, inplace =True)\naux['metrostotalesCorregidos'] = aux[['metrostotales', 'metroscubiertos']].max(axis=1)\naux['metroscubiertosCorregidos'] = aux[['metrostotales', 'metroscubiertos']].min(axis=1)\ndf['metrostotales'] = aux['metrostotalesCorregidos']\ndf['metroscubiertos'] = aux['metroscubiertosCorregidos']","execution_count":187,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fecha'] = pd.to_datetime(df['fecha'])\ndf['dia'] = df.fecha.dt.day\ndf['mes'] = df.fecha.dt.month\ndf['anio'] = df.fecha.dt.year\ndf.drop(columns=['fecha'], inplace=True)","execution_count":188,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['publicacionesPorCiudad'] = CountEncoder().fit_transform(df['ciudad'])","execution_count":189,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['publicacionesPorProvincia'] = CountEncoder().fit_transform(df['provincia'])","execution_count":190,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['publicacionesPorTipo'] = CountEncoder().fit_transform(df['tipodepropiedad'])\ndf['publicacionesPorZona'] = CountEncoder().fit_transform(df['idzona'])\ndf['publicacionesPorBanos'] = CountEncoder().fit_transform(df['banos'])\ndf['publicacionesPorHabitaciones'] = CountEncoder().fit_transform(df['habitaciones'])\ndf['publicacionesPorAntiguedad'] = CountEncoder().fit_transform(df['antiguedad'])","execution_count":191,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['tipodepropiedad','provincia','ciudad']].isna().sum()","execution_count":192,"outputs":[{"output_type":"execute_result","execution_count":192,"data":{"text/plain":"tipodepropiedad    0\nprovincia          0\nciudad             0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Datos por grupo"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['promedioAntiguedadZona'] = df.groupby('idzona')['antiguedad'].transform(np.mean)\ndf['promedioAntiguedadCiudad'] = df.groupby('ciudad')['antiguedad'].transform(np.mean)\ndf['promedioHabitacionesZona'] = df.groupby('idzona')['habitaciones'].transform(np.mean)\ndf['promedioHabitacionesCiudad'] = df.groupby('ciudad')['habitaciones'].transform(np.mean)\ndf['promedioMetrosCubiertosZona'] = df.groupby('idzona')['metroscubiertos'].transform(np.mean)\ndf['promedioMetrosCubiertosCiudad'] = df.groupby('ciudad')['metroscubiertos'].transform(np.mean)\ndf['promedioMetrosTotalesZona'] = df.groupby('idzona')['metrostotales'].transform(np.mean)\ndf['promedioMetrosTotalesCiudad'] = df.groupby('ciudad')['metrostotales'].transform(np.mean)\ndf['promedioPrecioPorProvincia'] = df.groupby('provincia')['precio'].transform(np.mean)\ndf['promedioPrecioPorIdzona'] = df.groupby('idzona')['precio'].transform(np.mean)\ndf['promedioPrecioPorCiudad'] = df.groupby('ciudad')['precio'].transform(np.mean)","execution_count":193,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = train[['provincia', 'ciudad', 'idzona','precio', 'metrostotales']].copy()\naux['precioXM2'] = aux['precio'] / aux['metrostotales']\ndf['promedioPXM2prov'] = aux.groupby('provincia')['precioXM2'].transform(np.mean)\ndf['promedioPXM2zona'] = aux.groupby('idzona')['precioXM2'].transform(np.mean)\ndf['promedioPXM2ciudad'] = aux.groupby('ciudad')['precioXM2'].transform(np.mean)\ndf['ciudadSobreCiudad'] = df['promedioPXM2ciudad'] / df['promedioPXM2prov']\ndf['promedioPromediosPXM2'] = (0.3*df['promedioPXM2prov'] + 0.4*df['promedioPXM2zona'] + 0.3*df['promedioPXM2ciudad']) / 3","execution_count":194,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Texto"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.titulo.fillna('', inplace=True)\ndf.descripcion.fillna('', inplace=True)\ndf[\"titulo_descripcion\"] = df[\"titulo\"].astype(str) + \" \" + df[\"descripcion\"].astype(str)\n#Como tiene algunos nulos los relleno con cadenas vaicas\ndf[\"titulo_descripcion\"].fillna(\"\",inplace = True)\n#REMUEVO LA PUNTUACION\nimport string\nprint(string.punctuation)\ntabla = {}\nfor c in string.punctuation + \"¿¡\":\n    tabla[ord(c)] = None\ndef sacar_puntuacion(s):\n    return s.translate(tabla)\ndf[\"titulo_descripcion\"] = df[\"titulo_descripcion\"].apply(sacar_puntuacion)\n#Agrego los primeros features\ndf[\"nro_palabras\"] = df[\"titulo_descripcion\"].apply(lambda x: len(x.split(\" \")))\ndf[\"nro_caracteres\"] = df[\"titulo_descripcion\"].apply(lambda x: len(x))\ndf[\"long_prom_palabra\"] = df[\"nro_caracteres\"] / df[\"nro_palabras\"]\n\ndef llenarDiccionario(diccionario,descripcion):\n    for palabra in descripcion.split():\n        diccionario[palabra] = diccionario.get(palabra,0) + 1\n        \ndef generarDiccionario(df2):\n    dicc = {}\n    for descripcion in df2['titulo_descripcion']:\n        if isinstance(descripcion,str): llenarDiccionario(dicc,descripcion)\n    return dicc\ncontador_palabras = generarDiccionario(df)\n\n#Elimino las stopwords = palabras vacias que no suman nada\nfrom nltk.corpus import stopwords\npalabras_vacias = stopwords.words('spanish')\n\nfor palabra  in palabras_vacias:\n    if palabra in contador_palabras:\n        del contador_palabras[palabra]\nordenados = sorted(contador_palabras.items(),key = lambda x: -x[1])\ntop_50 = dict(ordenados[:50])\n\n#Nuevos features\ndef contar_palabras_en_top(texto):\n    palabras = texto.split()\n    cont = 0\n    for palabra in palabras:\n        if palabra in top_50:\n            cont += 1\n    return cont\ndf[\"nro_palabras_mas_comunes\"] = df[\"titulo_descripcion\"].apply(contar_palabras_en_top)","execution_count":null,"outputs":[{"output_type":"stream","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [    \n       'id', \n    'antiguedad',\n       'habitaciones', 'garages', 'banos', 'metroscubiertos', 'metrostotales',\n       'idzona', 'lat', 'lng', 'gimnasio', 'usosmultiples', 'piscina',\n       'escuelascercanas', 'centroscomercialescercanos',\n       'dia', 'mes', 'anio',\n        #Canti de publicaciones\n        'publicacionesPorCiudad',\n       'publicacionesPorProvincia', 'publicacionesPorTipo',\n        'publicacionesPorZona','publicacionesPorBanos',\n        'publicacionesPorHabitaciones', 'publicacionesPorAntiguedad',\n            \n        #Texto\n        \"nro_palabras\", \"nro_caracteres\", \"long_prom_palabra\", \"nro_palabras_mas_comunes\",\n         #Promedios\n        'promedioAntiguedadZona', 'promedioAntiguedadCiudad',\n        'promedioHabitacionesZona', 'promedioHabitacionesCiudad',\n        'promedioMetrosCubiertosZona','promedioMetrosCubiertosCiudad',\n        'promedioMetrosTotalesZona', 'promedioMetrosTotalesCiudad', \n        'promedioPrecioPorProvincia', 'promedioPrecioPorIdzona', \n        'promedioPrecioPorCiudad',\n        #'promedioPXM2prov',\n        'promedioPXM2zona',\n        #'promedioPXM2ciudad',\n        'ciudadSobreCiudad',\n            #'promedioPxM2Provincia',\n        \n         'ciudad','tipodepropiedad', 'provincia', ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntransformador_categorias = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', categories = categorias)),\n])\n\ntransformador_numeros = Pipeline(steps=[('a', SimpleImputer(strategy = 'median')),\n                                        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def obtenerFeaturesCategoricos(features):\n    l = []\n    for feature in features:\n        if not np.issubdtype(df[feature].dtype, np.number):\n            l.append(feature)\n    return l\n\nnum_features = list(df[features].select_dtypes(include=[np.number]).columns)\n\ncat_features = list(obtenerFeaturesCategoricos(features))\nprint (\"Features numericos:\", num_features, '\\nFeatures categoricos: ', cat_features)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', transformador_numeros, num_features),\n        ('cat', transformador_categorias, cat_features)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', transformador_numeros, num_features),\n        ('cat', transformador_categorias, cat_features)\n   ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.XGBRegressor(#learning_rate= 0.1,n_estimators= 1000,scale_pos_weight= 2,max_depth= 5,min_child_weight= 3,gamma= 0.0,colsample_bytree= 0.75,                     subsample= 0.7,colsample_bylevel= 0.65, \n    learning_rate= 0.03,n_estimators= 800,scale_pos_weight= 2,max_depth= 5,min_child_weight= 5, colsample_bytree= 0.5,subsample= 0.5,colsample_bylevel= 0.65, \n    tree_method='gpu_hist', gpu_id=0, eval_metric = \"mae\")\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#entrenamiento = df.head(240000).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prueba = df.tail(60000).copy()","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prueba.drop(columns=['precio'], inplace=True)","execution_count":125,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"entrenamiento = df\ntrain_x = entrenamiento[features].copy()\ntrain_y = entrenamiento.precio.copy()\ntrain_x, test_x, train_y, test_y = train_test_split(train_x, train_y,train_size=0.8, test_size=0.2)\nmy_pipeline.fit(train_x, train_y)","execution_count":126,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n","name":"stderr"},{"output_type":"stream","text":"[15:08:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","name":"stdout"},{"output_type":"execute_result","execution_count":126,"data":{"text/plain":"Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('a',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0))],\n                                                           verbose=False),\n                                                  ['id', 'antiguedad',\n                                                   'habitaciones',...\n                              colsample_bytree=0.5, eval_metric='mae', gamma=0,\n                              gpu_id=0, importance_type='gain',\n                              learning_rate=0.03, max_delta_step=0, max_depth=5,\n                              min_child_weight=5, missing=None,\n                              n_estimators=800, n_jobs=1, nthread=None,\n                              objective='reg:linear', random_state=0,\n                              reg_alpha=0, reg_lambda=1, scale_pos_weight=2,\n                              seed=None, silent=None, subsample=0.5,\n                              tree_method='gpu_hist', verbosity=1))],\n         verbose=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_train = my_pipeline.predict(train_x)\nerror_train = mean_absolute_error(preds_train, train_y)\nprint(\"Error en el dataset de train:\", error_train)\npreds_test = my_pipeline.predict(test_x)\nerror_test = mean_absolute_error(preds_test, test_y)\nprint(\"Error en el dataset de test:\", error_test)\nprint(\"Diferencia: \", error_test - error_train)","execution_count":127,"outputs":[{"output_type":"stream","text":"Error en el dataset de train: 505239.53528389486\nError en el dataset de test: 529861.2055695597\nDiferencia:  24621.670285664848\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRF_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('classifier', RandomForestClassifier(n_estimators = 1000, max_depth = 5))\n                             ])","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train,X_test,y_train,y_test = train_test_split(train_x, train_y,test_size=0.3, random_state = 0)\n#clf = RF_pipeline.fit(X_train, y_train)\n#importancia_de_features = RF_pipeline.steps[1][1].feature_importances_\n#for feature in sorted(zip(importancia_de_features,features),reverse=True):\n  #print(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.tipodepropiedad = train_x.tipodepropiedad.astype(str)\ntrain_x.provincia = train_x.provincia.astype(str)\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = my_pipeline.predict(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ping()\nmean_absolute_error(preds, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_finales = my_pipeline.predict(prueba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(preds_finales, index=prueba.id, columns=['precio'])\nres.reset_index(inplace=True)\nres.columns = [\"id\", \"target\"]\ndisplay(res.head())\n# RMSLE=1.0249284784393988 ?\n\n\n# import the modules we'll need\nfrom IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"knn-results.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_x, train_y,train_size=0.8, random_state = 0)\nx_train_procesado = preprocessor.fit_transform(x_train)\nx_val_procesado = preprocessor.fit_transform(x_val)\nmy_pipeline.fit(x_train,y_train, model__eval_set=[(x_train_procesado, y_train.to_numpy()), (x_val_procesado, y_val.to_numpy())])\npreds = my_pipeline.predict(x_val)\npredictions = [round(value) for value in preds]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evals_result()\ndisplay(\"Maxima diferencia al final: \" + str(results['validation_1']['mae'][-1] - results['validation_0']['mae'][-1]))\nepochs = len(results['validation_0']['mae'])\nx_axis = range(0, epochs)\n# plot log loss\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['mae'], label='Train')\nax.plot(x_axis, results['validation_1']['mae'], label='Test')\nax.legend()\nplt.ylabel('mae')\nplt.title('XGBoost mae')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RandomizedSearchCV\nparam_dist = {'n_estimators': stats.randint(600, 2000),\n              'learning_rate': stats.uniform(0.01, 0.1),\n              'subsample': stats.uniform(0.3, 0.7),\n              'max_depth': [3, 4, 5, 6, 7],\n              'colsample_bytree': stats.uniform(0.5, 0.45),\n              'min_child_weight': [3, 4, 5, 6]\n             }\nmodel = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0, eval_metric = \"mae\")\nclf = RandomizedSearchCV(model, param_distributions = param_dist, n_iter = 5, error_score = 0, verbose = 3)\n\nnumFolds = 5\nfolds = KFold(n_splits = numFolds, shuffle = True)\n\nentrenamiento = df.head(240000).copy()\nX = entrenamiento[features].copy()\ny = entrenamiento.precio.copy()\nestimators = []\nresults = np.zeros(len(train_x))\nscore = 0.0\nfor train_index, test_index in folds.split(X):\n    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n    y_train, y_test = y.iloc[train_index].values.ravel(), y.iloc[test_index].values.ravel()\n    x_train_procesado = preprocessor.fit_transform(X_train)\n    x_val_procesado = preprocessor.fit_transform(X_test)\n#    my_pipeline.fit(X_train, y_train)\n    clf.fit(x_train_procesado, y_train)\n\n    estimators.append(clf.best_estimator_)\n#    estimators.append(my_pipeline)\n#    results[test_index] = my_pipeline.predict(X_test)\n    results[test_index] = clf.predict(x_val_procesado)\n    score += mean_absolute_error(y_test, results[test_index])\nscore /= numFolds\nping()\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(results, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}